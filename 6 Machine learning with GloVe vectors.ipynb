{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Machine learning starting from GloVe\n",
    "\n",
    "In this notebook we'll augment the unigram model by using GloVe dense vector representations of words.  \n",
    "\n",
    "Dense representations like GloVe and word2vec are helpful because they have mapped the words into a shared conceptual space.  In these vector spaces, direction and distance have meaning.  Nearby words are similar to each other, and it is possible to solve analogies by looking at direction and distance between pairs of words. For some graphics and more details, check out the GloVe page: http://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import csv\n",
    "import string\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"data/sentiment_splits.p\", \"rb\") as f:\n",
    "    X_train, X_dev, X_test, y_train, y_dev, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM_DIM = 50 #using more dimensions should be better accuracy\n",
    "PATH_TO_GLOVE = \"../glove.6B/\" \n",
    "\n",
    "path_name = PATH_TO_GLOVE + \"glove.6B.{0}d.txt\".format(NUM_DIM) \n",
    "reader = csv.reader(open(path_name), delimiter=' ', quoting=csv.QUOTE_NONE)    \n",
    "glove = {line[0]: np.array(list(map(float, line[1: ]))) for line in reader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We want a dataset in which each example is an average of its \n",
    "# individual word embeddings\n",
    "\n",
    "def convert_to_vector(paragraph):    \n",
    "    unigrams = paragraph.split()\n",
    "    representation = np.zeros(NUM_DIM)\n",
    "    ctr = 0.\n",
    "    for word in unigrams:\n",
    "        if word in glove:\n",
    "            representation += glove[word]\n",
    "            ctr += 1\n",
    "    return representation/ctr\n",
    "\n",
    "def convert_dataset(dataset):\n",
    "    dataset_matrix = np.zeros((len(dataset), NUM_DIM))\n",
    "    for i,paragraph in enumerate(dataset):\n",
    "        dataset_matrix[i] = convert_to_vector(paragraph)\n",
    "    return dataset_matrix\n",
    "\n",
    "X_train_vector = convert_dataset(X_train)\n",
    "print X_train_vector.shape\n",
    "X_dev_vector = convert_dataset(X_dev)\n",
    "print X_dev_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "clf = linear_model.LogisticRegression()\n",
    "clf.fit(X_train_vector, y_train)\n",
    "y_dev_hat = clf.predict(X_dev_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's evaluate\n",
    "# No cross-validation this round, but we can use that in the \n",
    "# future to get a sense of the variability of the method\n",
    "from sklearn import metrics\n",
    "\n",
    "print \"Accuracy:\"\n",
    "print metrics.accuracy_score(y_dev, y_dev_hat)\n",
    "\n",
    "print\n",
    "\n",
    "print \"Classification metrics:\"\n",
    "print metrics.classification_report(y_dev, y_dev_hat)\n",
    "\n",
    "print \n",
    "\n",
    "print \"Confusion matrix:\"\n",
    "print \"(Rows are truth, columns are predictions)\"\n",
    "print metrics.confusion_matrix(y_dev, y_dev_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So blindly averaging word vectors isn't the best for assessing sentiment.\n",
    "\n",
    "What if instead we used the single word in the sentence that was closest to a set of \"positive words\"? Or what if our classification was based on the distance to the positive words vs. the negative words?  That's perhaps a better utilization of the dense vector representations altogether.  We'll turn to that next."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
